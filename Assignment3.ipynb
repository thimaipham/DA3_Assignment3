{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1a84e194",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, precision_score, recall_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02f9601e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('cs_bisnode_panel.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ec3868",
   "metadata": {},
   "source": [
    "# 1. Data Exploration & Data Featuring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9ee059",
   "metadata": {},
   "source": [
    "### 1.1. Construct Hold-out sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20c0c3bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of defaulted firms: 56\n",
      "Number of survived firms: 981\n",
      "Total firms: 1037\n",
      "Average sales (million EUR): 0.49020221792682\n",
      "Minimum sales (million EUR): 0.001070370361328125\n",
      "Maximum sales (million EUR): 9.576485\n"
     ]
    }
   ],
   "source": [
    "# Filter data for the industry of interest (Manufacture of computer, electronic and optical products) and for the year 2014\n",
    "data_filtered = data[(data['ind2'] == 26) & (data['year'] == 2014)]\n",
    "\n",
    "# Filter SMEs with sales between 1000 EUR and 10 million EUR in 2014\n",
    "sme_2014 = data_filtered[(data_filtered['sales'] >= 1000) & (data_filtered['sales'] <= 10e6)]\n",
    "\n",
    "# Prepare data for 2015 to check for existence and sales in 2015\n",
    "sales_2015_full = data[(data['ind2'] == 26) & (data['year'] == 2015)][['comp_id', 'sales']]\n",
    "\n",
    "# Identify SMEs from 2014 that either do not exist in 2015 or have sales equal to 0 in 2015\n",
    "sme_2014_comp_ids = sme_2014['comp_id'].unique()\n",
    "sales_2015_existence = sales_2015_full[sales_2015_full['comp_id'].isin(sme_2014_comp_ids)]\n",
    "\n",
    "# Firms that do not exist in 2015 data\n",
    "defaulted_firms_ids = sme_2014_comp_ids[~np.isin(sme_2014_comp_ids, sales_2015_existence['comp_id'])]\n",
    "\n",
    "# Firms with zero sales in 2015 from the list of existing firms\n",
    "defaulted_due_to_zero_sales = sales_2015_existence[sales_2015_existence['sales'].fillna(0) <= 0]['comp_id'].unique()\n",
    "\n",
    "# Combine the lists to get the final list of defaulted firms\n",
    "all_defaulted_firms_ids = np.unique(np.concatenate((defaulted_firms_ids, defaulted_due_to_zero_sales)))\n",
    "\n",
    "# Calculate the final numbers\n",
    "num_defaulted_final = len(all_defaulted_firms_ids)\n",
    "num_survived_final = len(sme_2014_comp_ids) - num_defaulted_final\n",
    "total_firms = len(sme_2014_comp_ids)\n",
    "average_sales = sme_2014['sales'].mean() / 1e6  # Convert to million EUR\n",
    "min_sales = sme_2014['sales'].min() / 1e6  # Convert to million EUR\n",
    "max_sales = sme_2014['sales'].max() / 1e6  # Convert to million EUR\n",
    "\n",
    "# Print the final results\n",
    "print(f\"Number of defaulted firms: {num_defaulted_final}\")\n",
    "print(f\"Number of survived firms: {num_survived_final}\")\n",
    "print(f\"Total firms: {total_firms}\")\n",
    "print(f\"Average sales (million EUR): {average_sales}\")\n",
    "print(f\"Minimum sales (million EUR): {min_sales}\")\n",
    "print(f\"Maximum sales (million EUR): {max_sales}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c649436",
   "metadata": {},
   "source": [
    "### 1.2. Design data sample for training and testing\n",
    "- Filter Data for Years Before 2014: Select data from 2013 and earlier. This ensures that we do not use any information from the hold-out sample for training the model.\n",
    "- Select Industry: Focus on industry ind2 == 26, similar to what we did with the hold-out sample.\n",
    "- Identifying SMEs: Just like with the hold-out sample, we will identify SMEs based on revenue in 2013."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad616904",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9689, 48),\n",
       "        comp_id  year         sales\n",
       " 960  6538183.0  2005  29288.888672\n",
       " 961  6538183.0  2006  35929.628906\n",
       " 962  6538183.0  2007  31729.628906\n",
       " 963  6538183.0  2008  35703.703125\n",
       " 964  6538183.0  2009  43062.964844)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Industry ind2 == 26 and years before 2014\n",
    "data_pre_2014 = data[(data['ind2'] == 26) & (data['year'] < 2014)]\n",
    "\n",
    "# Filter based on revernues from 1000 EUR đến 10M EUR\n",
    "sme_pre_2014 = data_pre_2014[(data_pre_2014['sales'] >= 1000) & (data_pre_2014['sales'] <= 10e6)]\n",
    "\n",
    "# Check the size of sample\n",
    "sme_pre_2014_shape = sme_pre_2014.shape\n",
    "sme_pre_2014_info = sme_pre_2014[['comp_id', 'year', 'sales']].head()\n",
    "\n",
    "(sme_pre_2014_shape, sme_pre_2014_info)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b75480d",
   "metadata": {},
   "source": [
    "### 1.3. Data Featuring and Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2407ea69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Current Ratio</th>\n",
       "      <th>Net Profit Margin</th>\n",
       "      <th>Debt to Equity Ratio</th>\n",
       "      <th>Firm Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>960</th>\n",
       "      <td>17.914893</td>\n",
       "      <td>-0.039074</td>\n",
       "      <td>0.046305</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>961</th>\n",
       "      <td>13.295082</td>\n",
       "      <td>0.015772</td>\n",
       "      <td>0.055886</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>962</th>\n",
       "      <td>3.415730</td>\n",
       "      <td>0.026497</td>\n",
       "      <td>0.298407</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963</th>\n",
       "      <td>4.665919</td>\n",
       "      <td>0.010477</td>\n",
       "      <td>0.179333</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>964</th>\n",
       "      <td>2.087973</td>\n",
       "      <td>0.034661</td>\n",
       "      <td>0.814187</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Current Ratio  Net Profit Margin  Debt to Equity Ratio  Firm Age\n",
       "960      17.914893          -0.039074              0.046305        21\n",
       "961      13.295082           0.015772              0.055886        21\n",
       "962       3.415730           0.026497              0.298407        21\n",
       "963       4.665919           0.010477              0.179333        21\n",
       "964       2.087973           0.034661              0.814187        21"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sme_pre_2014_filled = sme_pre_2014.copy()\n",
    "# Change type of `founded_date` column to datetime\n",
    "sme_pre_2014_filled['founded_date'] = pd.to_datetime(sme_pre_2014_filled['founded_date'], errors='coerce')\n",
    "\n",
    "# Calculate `Firm Age` features\n",
    "sme_pre_2014_filled['Firm Age'] = 2013 - sme_pre_2014_filled['founded_date'].dt.year\n",
    "\n",
    "# Create indicator variables for columns with value 0\n",
    "for col in columns_with_zeros:\n",
    "    flag_col = col + '_flag'\n",
    "    sme_pre_2014_filled[flag_col] = (sme_pre_2014_filled[col] == 0).astype(int)\n",
    "    sme_pre_2014_filled[col].replace(0, np.nan, inplace=True) \n",
    "    \n",
    "# Calculate new features, using columns that have been edited to avoid dividing by zero\n",
    "sme_pre_2014_filled['Current Ratio'] = sme_pre_2014_filled['curr_assets'] / sme_pre_2014_filled['curr_liab']\n",
    "sme_pre_2014_filled['Net Profit Margin'] = sme_pre_2014_filled['profit_loss_year'] / sme_pre_2014_filled['sales']\n",
    "sme_pre_2014_filled['Debt to Equity Ratio'] = sme_pre_2014_filled['curr_liab'] / sme_pre_2014_filled['share_eq']\n",
    "\n",
    "# Show data after adding new features\n",
    "sme_pre_2014_filled[['Current Ratio', 'Net Profit Margin', 'Debt to Equity Ratio', 'Firm Age']].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e746bc29",
   "metadata": {},
   "source": [
    "# 2. Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d6608dc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7751, 4), (1938, 4), (7751,), (1938,), 0.034059242439880275)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate output labels based on default information\n",
    "# Mark defaulted businesses as 1 and non-defaulted businesses as 0\n",
    "# Create a new column 'Default' in the data, default value is 0 (no default)\n",
    "sme_pre_2014_filled['Default'] = 0\n",
    "\n",
    "# Flag defaulted firms based on all_defaulted_firms_ids\n",
    "sme_pre_2014_filled.loc[sme_pre_2014_filled['comp_id'].isin(all_defaulted_firms_ids), 'Default'] = 1\n",
    "\n",
    "# Check the corporate default rate in the data\n",
    "default_rate = sme_pre_2014_filled['Default'].mean()\n",
    "\n",
    "# Perform data division\n",
    "# Select input characteristics, remove 'comp_id', 'founded_date', and irrelevant columns or target data\n",
    "X_columns = ['Current Ratio', 'Net Profit Margin', 'Debt to Equity Ratio', 'Firm Age']  \n",
    "Y_column = 'Default'\n",
    "\n",
    "X = sme_pre_2014_filled[X_columns].fillna(0)  # Handle missing values by replacing them with 0\n",
    "Y = sme_pre_2014_filled[Y_column]\n",
    "\n",
    "# Divide data into training set and test set with ratio 80:20\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Check the size of the training set and test set\n",
    "(X_train.shape, X_test.shape, Y_train.shape, Y_test.shape, default_rate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c11e78f",
   "metadata": {},
   "source": [
    "### 2.1. Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "268250db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9658\n",
      "Test accuracy: 0.9665\n",
      "Train AUC: 0.525\n",
      "Test AUC: 0.4751\n"
     ]
    }
   ],
   "source": [
    "# Training logistic model\n",
    "logistic_model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "logistic_model.fit(X_train, Y_train)\n",
    "\n",
    "# Predicting\n",
    "Y_train_pred = logistic_model.predict(X_train)\n",
    "Y_test_pred = logistic_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy, AUC, Precision, Recall, F1-Score\n",
    "train_accuracy = round(accuracy_score(Y_train, Y_train_pred),4)\n",
    "test_accuracy = round(accuracy_score(Y_test, Y_test_pred),4)\n",
    "train_auc = round(roc_auc_score(Y_train, logistic_model.predict_proba(X_train)[:, 1]),4)\n",
    "test_auc = round(roc_auc_score(Y_test, logistic_model.predict_proba(X_test)[:, 1]),4)\n",
    "precision_logistic = round(precision_score(Y_test, Y_test_pred), 4)\n",
    "recall_logistic = round(recall_score(Y_test, Y_test_pred), 4)\n",
    "f1_score_logistic = round(f1_score(Y_test, Y_test_pred), 4)\n",
    "\n",
    "print(f'Train accuracy: {train_accuracy}')\n",
    "print(f'Test accuracy: {test_accuracy}')\n",
    "print(f'Train AUC: {train_auc}')\n",
    "print(f'Test AUC: {test_auc}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6772f61",
   "metadata": {},
   "source": [
    "- **High Accuracy but Low AUC**: The logistic regression model demonstrated high accuracy levels on both the training set (96.58%) and the test set (96.65%). However, the Area Under the Curve (AUC) scores were significantly lower, with 0.525 on the training set and 0.475 on the test set. This discrepancy indicates that while the model is accurate in predicting the majority class (non-defaulting firms), it struggles to distinguish effectively between the defaulting and non-defaulting firms.\n",
    "\n",
    "- **Impact of Class Imbalance**: The observed high accuracy alongside low AUC can largely be attributed to the class imbalance present in our dataset, where only about 3.41% of the firms defaulted. In such scenarios, accuracy can be misleading as a performance metric, since simply predicting the majority class for all observations would also yield high accuracy but poor model utility."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa567154",
   "metadata": {},
   "source": [
    "### 2.2. Random Forest model\n",
    "Based on the current situation and the results from the logistic regression model, a reasonable option is to experiment with a more complex model to see if it can improve the prediction performance, especially the AUC, in the context of imbalanced data. The Random Forest model is a good choice because it is not only powerful in handling imbalanced data but also has the ability to handle features with non-linear relationships and complex interactions between features well. display.\n",
    "\n",
    "##### Why Choose Random Forest?\n",
    "- **Ability to Handle Imbalanced Data**: Random Forest can improve performance on imbalanced data through its bagging mechanism and underlying decision trees.\n",
    "- **Nonlinear Feature Processing and Interaction**: This model is capable of automatically detecting and using nonlinear relationships and interactions between features without the need for complex feature engineering.\n",
    "- **Generalization Ability**: Random Forest generally shows good generalization ability and has a lower risk of overfitting than single decision tree models due to its ensemble mechanism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3cac578a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9994\n",
      "Test accuracy: 0.9675\n",
      "Train AUC: 1.0\n",
      "Test AUC: 0.7075\n"
     ]
    }
   ],
   "source": [
    "# Training the Random Forest model\n",
    "random_forest_model = RandomForestClassifier(random_state=42, n_estimators=100)\n",
    "random_forest_model.fit(X_train, Y_train)\n",
    "\n",
    "# Predicting on training set and test set\n",
    "Y_train_pred_rf = random_forest_model.predict(X_train)\n",
    "Y_test_pred_rf = random_forest_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy, AUC, Precision, Recall, F1-Score\n",
    "train_accuracy_rf = round(accuracy_score(Y_train, Y_train_pred_rf),4)\n",
    "test_accuracy_rf = round(accuracy_score(Y_test, Y_test_pred_rf), 4)\n",
    "train_auc_rf = round(roc_auc_score(Y_train, random_forest_model.predict_proba(X_train)[:, 1]), 4)\n",
    "test_auc_rf = round(roc_auc_score(Y_test, random_forest_model.predict_proba(X_test)[:, 1]), 4)\n",
    "precision_rf = round(precision_score(Y_test, Y_test_pred_rf), 4)\n",
    "recall_rf = round(recall_score(Y_test, Y_test_pred_rf), 4)\n",
    "f1_score_rf = round(f1_score(Y_test, Y_test_pred_rf), 4)\n",
    "\n",
    "print(f'Train accuracy: {train_accuracy_rf}')\n",
    "print(f'Test accuracy: {test_accuracy_rf}')\n",
    "print(f'Train AUC: {train_auc_rf}')\n",
    "print(f'Test AUC: {test_auc_rf}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa56f22",
   "metadata": {},
   "source": [
    "- **Significant Improvement in AUC**: The Random Forest model showed a significant improvement in the Area Under the Curve (AUC) on the test set, increasing from 0.475 (as observed with the logistic regression model) to 0.7075. This indicates a much better ability to distinguish between defaulting and non-defaulting firms.\n",
    "\n",
    "- **High Accuracy Maintained**: Despite the complexities introduced by the Random Forest model, it maintained a high level of accuracy on the test set (96.75%), similar to the logistic regression model. This suggests that the model is robust in predicting outcomes even with the imbalanced nature of the dataset.\n",
    "\n",
    "- **Exceptional Training Performance**: The model achieved near-perfect performance on the training set, with an accuracy of 99.94% and an AUC of 1.0. While this showcases the model's capability to fit the training data closely, it also prompts consideration for potential overfitting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262077cc",
   "metadata": {},
   "source": [
    "### 2.3. Gradient Boosting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "148581e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9693\n",
      "Test accuracy: 0.9649\n",
      "Train AUC: 0.8703\n",
      "Test AUC: 0.6985\n"
     ]
    }
   ],
   "source": [
    "# Training Gradient Boosting model\n",
    "gradient_boosting_model = GradientBoostingClassifier(random_state=42)\n",
    "gradient_boosting_model.fit(X_train, Y_train)\n",
    "# Predicting\n",
    "Y_train_pred_gb = gradient_boosting_model.predict(X_train)\n",
    "Y_test_pred_gb = gradient_boosting_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy and AUC\n",
    "train_accuracy_gb = round(accuracy_score(Y_train, Y_train_pred_gb), 4)\n",
    "test_accuracy_gb = round(accuracy_score(Y_test, Y_test_pred_gb), 4)\n",
    "train_auc_gb = round(roc_auc_score(Y_train, gradient_boosting_model.predict_proba(X_train)[:, 1]), 4)\n",
    "test_auc_gb = round(roc_auc_score(Y_test, gradient_boosting_model.predict_proba(X_test)[:, 1]), 4)\n",
    "precision_gb = round(precision_score(Y_test, Y_test_pred_gb), 4)\n",
    "recall_gb = round(recall_score(Y_test, Y_test_pred_gb), 4)\n",
    "f1_score_gb = round(f1_score(Y_test, Y_test_pred_gb), 4)\n",
    "\n",
    "print(f'Train accuracy: {train_accuracy_gb}')\n",
    "print(f'Test accuracy: {test_accuracy_gb}')\n",
    "print(f'Train AUC: {train_auc_gb}')\n",
    "print(f'Test AUC: {test_auc_gb}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0d8899",
   "metadata": {},
   "source": [
    "- **High Accuracy on Training and Test Sets**: The Gradient Boosting model achieved an accuracy of 96.93% on the training set and 96.49% on the test set. These results suggest that the model is able to predict with high reliability whether a firm will default or not, considering the entire dataset.\n",
    "\n",
    "- **AUC Performance**: The model's AUC on the training set is 0.870, indicating a strong capability to distinguish between the defaulting and non-defaulting firms during training. The AUC on the test set is 0.699, which, while lower than the training AUC, still represents a reasonable ability to generalize and differentiate between the two outcomes in unseen data.\n",
    "\n",
    "- **Comparison with Other Models**: When compared to the logistic regression and Random Forest models previously trained, the Gradient Boosting model presents a competitive AUC on the test set, signifying its potential as a robust predictive model for firm defaults.\n",
    "\n",
    "- **Consideration of Overfitting**: There is a noticeable difference between the AUC scores on the training and test sets, which may suggest some overfitting. This could warrant further investigation and potential model tuning to ensure that the model generalizes well to new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d753991d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Train AUC</th>\n",
       "      <th>Test AUC</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.9658</td>\n",
       "      <td>0.9665</td>\n",
       "      <td>0.5250</td>\n",
       "      <td>0.4751</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.9994</td>\n",
       "      <td>0.9675</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.7075</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.0312</td>\n",
       "      <td>0.0597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.9693</td>\n",
       "      <td>0.9649</td>\n",
       "      <td>0.8703</td>\n",
       "      <td>0.6985</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Train Accuracy  Test Accuracy  Train AUC  Test AUC  \\\n",
       "0  Logistic Regression          0.9658         0.9665     0.5250    0.4751   \n",
       "1        Random Forest          0.9994         0.9675     1.0000    0.7075   \n",
       "2    Gradient Boosting          0.9693         0.9649     0.8703    0.6985   \n",
       "\n",
       "   Precision  Recall  F1 Score  \n",
       "0     0.0000  0.0000    0.0000  \n",
       "1     0.6667  0.0312    0.0597  \n",
       "2     0.0000  0.0000    0.0000  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the results\n",
    "model_results = pd.DataFrame({\n",
    "    'Model': ['Logistic Regression', 'Random Forest', 'Gradient Boosting'],\n",
    "    'Train Accuracy': [train_accuracy, train_accuracy_rf, train_accuracy_gb],\n",
    "    'Test Accuracy': [test_accuracy, test_accuracy_rf, test_accuracy_gb],\n",
    "    'Train AUC': [train_auc, train_auc_rf, train_auc_gb],\n",
    "    'Test AUC': [test_auc, test_auc_rf, test_auc_gb],\n",
    "    'Precision': [precision_logistic, precision_rf, precision_gb],\n",
    "    'Recall': [recall_logistic, recall_rf, recall_gb],\n",
    "    'F1 Score': [f1_score_logistic, f1_score_rf, f1_score_gb]\n",
    "})\n",
    "\n",
    "model_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903c364a",
   "metadata": {},
   "source": [
    "##### Observations:\n",
    "- Random Forest leads in terms of AUC on the test set and is the only model with positive Precision and F1 Score, although these values are still quite low. This indicates that the model has the best ability to distinguish between classes among the three models.\n",
    "- Gradient Boosting also shows a relatively high Test AUC; however, like Logistic Regression, it fails to successfully detect default cases (with Precision, Recall, and F1 Score all being 0).\n",
    "- All three models exhibit high Test Accuracy, reflecting the ease of correctly predicting the dominant class in imbalanced data. However, this metric does not fully reflect the model's performance in detecting default cases.\n",
    "\n",
    "##### Conclusion:\n",
    "In this specific context, Random Forest appears to be the best choice based on its ability to differentiate between classes and some success in detecting default cases. However, the need to improve the detection of default cases is clear and should be a focus in the next steps of the model development process.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8873633",
   "metadata": {},
   "source": [
    "# 3. Apply model into hold-out sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fecf4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
